{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import FeatureSpace\n",
    "\n",
    "# simple customization\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical features encoded as integers\n",
    "        \"sex\": \"integer_categorical\",\n",
    "        \"cp\": \"integer_categorical\",\n",
    "        \"fbs\": \"integer_categorical\",\n",
    "        \"restecg\": \"integer_categorical\",\n",
    "        \"exang\": \"integer_categorical\",\n",
    "        \"ca\": \"integer_categorical\",\n",
    "        # Categorical feature encoded as string\n",
    "        \"thal\": \"string_categorical\",\n",
    "        # Numerical features to discretize\n",
    "        \"age\": \"float_discretized\",\n",
    "        # Numerical features to normalize\n",
    "        \"trestbps\": \"float_normalized\",\n",
    "        \"chol\": \"float_normalized\",\n",
    "        \"thalach\": \"float_normalized\",\n",
    "        \"oldpeak\": \"float_normalized\",\n",
    "        \"slope\": \"float_normalized\",\n",
    "    },\n",
    "    # We create additional features by hashing\n",
    "    # value co-occurrences for the\n",
    "    # following groups of categorical features.\n",
    "    crosses=[(\"sex\", \"age\"), (\"thal\", \"ca\")],\n",
    "    # The hashing space for these co-occurrences\n",
    "    # wil be 32-dimensional.\n",
    "    crossing_dim=32,\n",
    "    # Our utility will one-hot encode all categorical\n",
    "    # features and concat all features into a single\n",
    "    # vector (one vector per sample).\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more customization\n",
    "\n",
    "\n",
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical features encoded as integers\n",
    "        \"sex\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"cp\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"fbs\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"restecg\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"exang\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"ca\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        # Categorical feature encoded as string\n",
    "        \"thal\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        # Numerical features to normalize\n",
    "        \"age\": FeatureSpace.float_discretized(num_bins=30),\n",
    "        # Numerical features to normalize\n",
    "        \"trestbps\": FeatureSpace.float_normalized(),\n",
    "        \"chol\": FeatureSpace.float_normalized(),\n",
    "        \"thalach\": FeatureSpace.float_normalized(),\n",
    "        \"oldpeak\": FeatureSpace.float_normalized(),\n",
    "        \"slope\": FeatureSpace.float_normalized(),\n",
    "    },\n",
    "    # Specify feature cross with a custom crossing dim.\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(feature_names=(\"sex\", \"age\"), crossing_dim=64),\n",
    "        FeatureSpace.cross(\n",
    "            feature_names=(\"thal\", \"ca\"),\n",
    "            crossing_dim=16,\n",
    "        ),\n",
    "    ],\n",
    "    output_mode=\"concat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.fit(\n",
    "    preprocessed_train_ds, epochs=20, validation_data=preprocessed_val_ds, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = inference_model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    f\"This particular patient had a {100 * predictions[0][0]:.2f}% probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
